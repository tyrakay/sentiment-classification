{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2S8I2ny-ovS"
   },
   "source": [
    "# ANLP Assignment: Sentiment Classification\n",
    "\n",
    "In this assignment, you will be investigating NLP methods for distinguishing positive and negative reviews written about movies.\n",
    "\n",
    "For assessment, you are expected to complete and submit this notebook file.  When answers require code, you may import and use library functions (unless explicitly told otherwise).  All of your own code should be included in the notebook rather than imported from elsewhere.  Written answers should also be included in the notebook.  You should insert as many extra cells as you want and change the type between code and markdown as appropriate.\n",
    "\n",
    "In order to avoid misconduct, you should not talk about the assignment questions with your peers.  If you are not sure what a question is asking you to do or have any other questions, please ask me or one of the Teaching Assistants.\n",
    "\n",
    "Marking guidelines are provided as a separate document.\n",
    "\n",
    "The first few cells contain code to set-up the assignment and bring in some data.   In order to provide unique datasets for analysis by different students, you must enter your candidate number in the following cell.  Otherwise do not change the code in these cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "1gXQAZas-l9c"
   },
   "outputs": [],
   "source": [
    "candidateno=277161 #this MUST be updated to your candidate number so that you get a unique data sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nk8JTP88A8vs",
    "outputId": "5ce22518-19d8-4c38-b8f9-13732a3c7a44"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/tyrakoranteng/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tyrakoranteng/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /Users/tyrakoranteng/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('movie_reviews')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import movie_reviews\n",
    "import random\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from itertools import zip_longest\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.classify.api import ClassifierI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BHBkzAccCVaZ"
   },
   "outputs": [],
   "source": [
    "def split_data(data, ratio=0.7): # when the second argument is not given, it defaults to 0.7\n",
    "    \"\"\"\n",
    "    Given corpus generator and ratio:\n",
    "     - partitions the corpus into training data and test data, where the proportion in train is ratio,\n",
    "\n",
    "    :param data: A corpus generator.\n",
    "    :param ratio: The proportion of training documents (default 0.7)\n",
    "    :return: a pair (tuple) of lists where the first element of the\n",
    "            pair is a list of the training data and the second is a list of the test data.\n",
    "    \"\"\"\n",
    "\n",
    "    data = list(data)\n",
    "    n = len(data)\n",
    "    train_indices = random.sample(range(n), int(n * ratio))\n",
    "    test_indices = list(set(range(n)) - set(train_indices))\n",
    "    train = [data[i] for i in train_indices]\n",
    "    test = [data[i] for i in test_indices]\n",
    "    return (train, test)\n",
    "\n",
    "\n",
    "def get_train_test_data():\n",
    "\n",
    "    #get ids of positive and negative movie reviews\n",
    "    pos_review_ids=movie_reviews.fileids('pos')\n",
    "    neg_review_ids=movie_reviews.fileids('neg')\n",
    "\n",
    "    #split positive and negative data into training and testing sets\n",
    "    pos_train_ids, pos_test_ids = split_data(pos_review_ids)\n",
    "    neg_train_ids, neg_test_ids = split_data(neg_review_ids)\n",
    "    #add labels to the data and concatenate\n",
    "    training = [(movie_reviews.words(f),'pos') for f in pos_train_ids]+[(movie_reviews.words(f),'neg') for f in neg_train_ids]\n",
    "    testing = [(movie_reviews.words(f),'pos') for f in pos_test_ids]+[(movie_reviews.words(f),'neg') for f in neg_test_ids]\n",
    "\n",
    "    return training, testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1N3LWwBYICPP"
   },
   "source": [
    "When you have run the cell below, your unique training and testing samples will be stored in `training_data` and `testing_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "HJLegkdPFUJA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount of training data is 1400\n",
      "The amount of testing data is 600\n",
      "The representation of a single data item is below\n",
      "(['bob', 'the', 'happy', 'bastard', \"'\", 's', 'quickie', ...], 'pos')\n"
     ]
    }
   ],
   "source": [
    "#do not change the code in this cell\n",
    "random.seed(candidateno)\n",
    "training_data,testing_data=get_train_test_data()\n",
    "print(\"The amount of training data is {}\".format(len(training_data)))\n",
    "print(\"The amount of testing data is {}\".format(len(testing_data)))\n",
    "print(\"The representation of a single data item is below\")\n",
    "print(training_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RbTq6eGv2XT2"
   },
   "source": [
    "1)  \n",
    "a) **Generate** a list of 10 content words which are representative of the positive reviews in your training data.\n",
    "\n",
    "b) **Generate** a list of 10 content words which are representative of the negative reviews in your training data.\n",
    "\n",
    "c) **Explain** what you have done and why\n",
    "\n",
    "[20\\%]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "JXHrtNCg2XT4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Representative Content Words in Positive Reviews:\n",
      "['film', 'one', 'movie', 'like', 'good', 'story', 'also', 'time', 'even', 'well']\n"
     ]
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "\n",
    " # Convert each word to lowercase and remove punctuation\n",
    "def preprocess_words(words):\n",
    "    \n",
    "    remove_punctuation = [word.lower() for word in words if word.isalpha()]\n",
    "    \n",
    "# Filter out stop words from the list of words    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    content_words = [word for word in remove_punctuation if word not in stop_words]\n",
    "    \n",
    "    return content_words\n",
    "\n",
    "# Create an empty list to store positive words\n",
    "positive_words = []\n",
    "\n",
    "# Iterate through training data, extract positive words, and preprocess them\n",
    "for words, label in training_data:\n",
    "    if label == 'pos':\n",
    "        positive_words.extend(preprocess_words(words))\n",
    "\n",
    "# Create a frequency distribution of positive words\n",
    "positive_freq_dist = FreqDist(positive_words)\n",
    "\n",
    "\n",
    "positive_content_words = [word for word, _ in positive_freq_dist.most_common(10)]\n",
    "\n",
    "print(\"10 Representative Content Words in Positive Reviews:\")\n",
    "print(positive_content_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "gvFu36xZ2XT5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Representative Content Words in Negative Reviews:\n",
      "['film', 'movie', 'one', 'like', 'even', 'good', 'time', 'get', 'would', 'much']\n"
     ]
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "\n",
    " # Convert each word to lowercase and remove punctuation\n",
    "def preprocess_words(words):\n",
    "    \n",
    "    remove_punctuation = [word.lower() for word in words if word.isalpha()]\n",
    "    \n",
    "# Filter out stop words from the list of words                \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    content_words = [word for word in remove_punctuation if word not in stop_words]\n",
    "    \n",
    "    return content_words\n",
    "\n",
    "# Create an empty list to store negative words\n",
    "negative_words = []\n",
    "\n",
    "# Iterate through training data, extract negative words, and preprocess them\n",
    "for words, label in training_data:\n",
    "    if label == 'neg':\n",
    "        negative_words.extend(preprocess_words(words))\n",
    "\n",
    "# Create a frequency distribution of negative words\n",
    "negative_freq_dist = FreqDist(negative_words)\n",
    "\n",
    "\n",
    "negative_content_words = [word for word, _ in negative_freq_dist.most_common(10)]\n",
    "\n",
    "print(\"10 Representative Content Words in Negative Reviews:\")\n",
    "print(negative_content_words)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RgePc9hV2XT_"
   },
   "source": [
    "This code extracts words from positive/negative reviews while preprocessing them, removing punctuation, converting to lowercase, and filtering out stopwords. This allows us to focus on words that are likely to represent the content of positive reviews without noise from punctuation and common words.\n",
    "\n",
    "We iterate through the training_data dataset, which contains pairs of words and labels.\n",
    "We check the label of each data point to filter for positive and negative reviews i.e. label == 'pos' & label == 'neg' respectively.\n",
    "For each positive/negative review, we extend the positive/negative words list with the preprocessed and cleaned words.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JauTzY5N2XUB"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TApOQE6vND20"
   },
   "source": [
    "2)\n",
    "a) **Use** the lists generated in Q1 to build a **word list classifier** which will classify reviews as being positive or negative.\n",
    "\n",
    "b) **Explain** what you have done.\n",
    "\n",
    "[12.5\\%]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "BThDMrcmODJy"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1: Classified as positive\n",
      "Review 2: Classified as None\n"
     ]
    }
   ],
   "source": [
    "# Representative words for positive and negative reviews\n",
    "positive_words = ['film', 'one', 'movie', 'like', 'good', 'story', 'also', 'time', 'even', 'well']\n",
    "negative_words = ['film', 'movie', 'one', 'like', 'even', 'good', 'time', 'get', 'would', 'much']\n",
    "\n",
    "# Function to classify a review as positive or negative\n",
    "def classify_review(review, positive_words, negative_words):\n",
    "    positive_count = sum(1 for word in review if word in positive_words)\n",
    "    negative_count = sum(1 for word in review if word in negative_words)\n",
    "    \n",
    "    if positive_count > negative_count:\n",
    "        return 'positive'\n",
    "    elif negative_count > positive_count:\n",
    "        return 'negative'\n",
    "    \n",
    "\n",
    "# Example reviews\n",
    "review1 = ['good', 'movie', 'enjoyed', 'story']\n",
    "review2 = ['boring', 'time', 'poor', 'plot']\n",
    "\n",
    "\n",
    "# Classify example reviews\n",
    "result1 = classify_review(review1, positive_words, negative_words)\n",
    "result2 = classify_review(review2, positive_words, negative_words)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Review 1: Classified as\", result1)\n",
    "print(\"Review 2: Classified as\", result2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The review is classified as: pos\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify.api import ClassifierI\n",
    "from nltk import FreqDist\n",
    "\n",
    "class SimpleClassifier(ClassifierI): \n",
    "    def __init__(self, pos, neg): \n",
    "        # Initialize the SimpleClassifier with positive and negative word lists\n",
    "        self._pos = set(pos) \n",
    "        self._neg = set(neg)\n",
    "\n",
    "    def classify(self, words): \n",
    "         # Calculate a score based on the presence of words in positive and negative lists\n",
    "        score = sum(1 if word in self._pos else -1 if word in self._neg else 0 for word in words)\n",
    "        \n",
    "        # Classify the review as \"pos\" if the score is positive, otherwise \"neg\"\n",
    "        return \"pos\" if score > 0 else \"neg\"\n",
    "\n",
    "    def labels(self): \n",
    "         # Return the labels used by the classifier (\"pos\" and \"neg\")\n",
    "        return (\"pos\", \"neg\")\n",
    "\n",
    "# Example usage\n",
    "positive_words = ['film', 'one', 'movie', 'like', 'good', 'story', 'also', 'time', 'even', 'well']\n",
    "negative_words = ['film', 'movie', 'one', 'like', 'even', 'good', 'time', 'get', 'would', 'much']\n",
    "\n",
    "# Create an instance of the SimpleClassifier\n",
    "classifier = SimpleClassifier(positive_words, negative_words)\n",
    "\n",
    "# Example classification\n",
    "review_text = \"This movie was great\"\n",
    "words_in_review = review_text.lower().split()  # assuming you want case-insensitive matching\n",
    "classification = classifier.classify(words_in_review)\n",
    "print(f\"The review is classified as: {classification}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code defines a simple sentiment classifier, `SimpleClassifier`, as a subclass of the NLTK `ClassifierI`. It is initialized with two sets of words, one representing positive sentiments (`_pos`) and the other negative sentiments (`_neg`). \n",
    "\n",
    "The `classify` method takes a list of words as input, assigns a score based on the presence of words in the positive and negative sets, and classifies the input as \"pos\" if the score is positive and \"neg\" otherwise. \n",
    "\n",
    "The `labels` method returns the possible classification labels used by the classifier, which are \"pos\" and \"neg.\" \n",
    "\n",
    "This classifier operates on the basic principle of counting positive and negative words in a given text to determine its sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C6vK5Vyz2XUF"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YZdDO_Y92XUH"
   },
   "source": [
    "3)\n",
    "a) **Calculate** the accuracy, precision, recall and F1 score of your classifier.\n",
    "\n",
    "b) Is it reasonable to evaluate the classifier in terms of its accuracy?  **Explain** your answer and give a counter-example (a scenario where it would / would not be reasonable to evaluate the classifier in terms of its accuracy).\n",
    "\n",
    "[20\\%]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "1LQc8bsA2XUI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier Accuracy: 49.83%\n"
     ]
    }
   ],
   "source": [
    "def classifier_evaluate(cls, testing_data):\n",
    "    acc = 0\n",
    "    docs, gold_standard = zip(*testing_data)\n",
    "\n",
    "    # Pass all of the docs to the classifier and get back a list of predictions\n",
    "    predictions = cls.classify_many(docs)\n",
    "\n",
    "    # Zip the predictions with the gold standard labels and compare\n",
    "    for prediction, gold_label in zip(predictions, gold_standard):\n",
    "        if prediction == gold_label:\n",
    "            acc += 1\n",
    "\n",
    "    return acc / len(testing_data)\n",
    "\n",
    "#Calculate accuracy\n",
    "accuracy = classifier_evaluate(classifier, testing_data)\n",
    "print(f\"Classifier Accuracy: {accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "R_i80ceP2XUJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 49.92%\n",
      "Recall: 99.33%\n",
      "F1 Score: 66.44%\n"
     ]
    }
   ],
   "source": [
    "class ConfusionMatrix:\n",
    "    def __init__(self, predictions, gold_standard, classes=(\"pos\", \"neg\")):\n",
    "        \n",
    "        # Initialize the ConfusionMatrix object with predicted and actual labels\n",
    "        (self.c1, self.c2) = classes\n",
    "        \n",
    "        self.TP = 0 # True Positives (correctly predicted positive instances)\n",
    "        self.FP = 0 # False Positives (incorrectly predicted positive instances)\n",
    "        self.FN = 0 # False Negatives (incorrectly predicted negative instances)\n",
    "        self.TN = 0 # True Negatives (correctly predicted negative instances)\n",
    "\n",
    "        for p, g in zip(predictions, gold_standard):\n",
    "            if g == self.c1:\n",
    "                if p == self.c1:\n",
    "                    self.TP += 1\n",
    "                else:\n",
    "                    self.FN += 1\n",
    "            elif p == self.c1:\n",
    "                self.FP += 1\n",
    "            else:\n",
    "                self.TN += 1\n",
    "\n",
    "    def precision(self):\n",
    "        # Precision is the ratio of correctly predicted positive observations to the total predicted positives\n",
    "        return self.TP / (self.TP + self.FP) if (self.TP + self.FP) != 0 else 0\n",
    "\n",
    "    def recall(self):\n",
    "        # Recall is the ratio of correctly predicted positive observations to all the actual positives\n",
    "        return self.TP / (self.TP + self.FN) if (self.TP + self.FN) != 0 else 0\n",
    "\n",
    "    def f1(self):\n",
    "        # F1 Score is the weighted average of Precision and Recall\n",
    "        precision = self.precision()\n",
    "        recall = self.recall()\n",
    "        return (2 * precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "    \n",
    "\n",
    "docs, gold_standard = zip(*testing_data)\n",
    "\n",
    "# Pass all of the docs to the classifier and get back a list of predictions\n",
    "predictions = classifier.classify_many(docs)\n",
    "\n",
    "# Create a ConfusionMatrix instance\n",
    "conf_matrix = ConfusionMatrix(predictions, gold_standard)\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision = conf_matrix.precision()\n",
    "recall = conf_matrix.recall()\n",
    "f1_score = conf_matrix.f1()\n",
    "\n",
    "print(f\"Precision: {precision:.2%}\")\n",
    "print(f\"Recall: {recall:.2%}\")\n",
    "print(f\"F1 Score: {f1_score:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "VbYwwhcs2XUL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution in Training Data:\n",
      "{'pos': 700, 'neg': 700}\n",
      "\n",
      "Class Distribution in Testing Data:\n",
      "{'pos': 300, 'neg': 300}\n"
     ]
    }
   ],
   "source": [
    "def calculate_class_distribution(data):\n",
    "    class_counts = {}\n",
    "    \n",
    "    for _, label in data:\n",
    "        if label in class_counts:\n",
    "            class_counts[label] += 1\n",
    "        else:\n",
    "            class_counts[label] = 1\n",
    "\n",
    "    return class_counts\n",
    "\n",
    "\n",
    "training_class_distribution = calculate_class_distribution(training_data)\n",
    "testing_class_distribution = calculate_class_distribution(testing_data)\n",
    "\n",
    "print(\"Class Distribution in Training Data:\")\n",
    "print(training_class_distribution)\n",
    "\n",
    "print(\"\\nClass Distribution in Testing Data:\")\n",
    "print(testing_class_distribution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the provided class distributions, where both the training and testing datasets have approximately equal representation of positive ('pos') and negative ('neg') instances, it is reasonable to evaluate the classifier in terms of accuracy. The balanced nature of the datasets allows accuracy to provide a meaningful overall assessment of the classifier's performance, as it considers both classes equally.\n",
    "\n",
    "In this case, accuracy would give a fair representation of how well the classifier is performing across both positive and negative instances. The classifier's ability to correctly classify instances from both classes would be reflected accurately in the accuracy metric.\n",
    "\n",
    "Counterexample where Accuracy might not be Reasonable:\n",
    "If the class distribution were heavily imbalanced, with a significant majority of instances belonging to one class, accuracy might not be a suitable metric. For instance, if 90% of instances were labeled as 'pos' and only 10% as 'neg', a classifier that predicts 'pos' for all instances could achieve a high accuracy (90%). However, such a model would not be useful, especially if the goal is to correctly identify instances of the minority class ('neg'). In imbalanced scenarios, precision, recall, and F1 score become more informative metrics for evaluating classifier performance, as they provide insights into how well the model handles the minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVZp0N5J2XUL"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIS9UpmJNEAp"
   },
   "source": [
    "4)\n",
    "a)  **Construct** a Naive Bayes classifier (e.g., from NLTK).\n",
    "\n",
    "b)  **Compare** the performance of your word list classifier with the Naive Bayes classifier.  **Discuss** your results.\n",
    "\n",
    "[12.5\\%]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Gwjig-Y12XUN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Classifier Accuracy: 63.83%\n"
     ]
    }
   ],
   "source": [
    "from nltk import NaiveBayesClassifier\n",
    "from nltk.classify import accuracy\n",
    "\n",
    "\n",
    "\n",
    "# Feature extraction\n",
    "def extract_features(words):\n",
    "    return dict([(word, True) for word in words])\n",
    "\n",
    "# Prepare training and testing sets\n",
    "training_set = [(extract_features(words), label) for words, label in training_data]\n",
    "testing_set = [(extract_features(words), label) for words, label in testing_data]\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "nb_classifier = NaiveBayesClassifier.train(training_set)\n",
    "\n",
    "# Evaluate the performance\n",
    "accuracy_nb = accuracy(nb_classifier, testing_set)\n",
    "\n",
    "print(f\"Naive Bayes Classifier Accuracy: {accuracy_nb:.2%}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3AUsYRMa2XUN"
   },
   "source": [
    "The results indicate that the Naive Bayes classifier outperforms the word list classifier in terms of accuracy, achieving 63.83% accuracy compared to the word list classifier's accuracy of 49.83%. The Naive Bayes classifier, which leverages probabilistic modeling based on word features, demonstrates better overall predictive performance on the testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bytPkuHf2XUO"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGDXaVDqOSfY"
   },
   "source": [
    "5)\n",
    "a) Design and **carry out an experiment** into the impact of the **length of the wordlists** on the wordlist classifier.  Make sure you **describe** design decisions in your experiment, include a **graph** of your results and **discuss** your conclusions.\n",
    "\n",
    "b) Would you **recommend** a wordlist classifier or a Naive Bayes classifier for future work in this area?  **Justify** your answer.\n",
    "\n",
    "[25\\%]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlxoUthX2XUP"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T1L7mZ-k2XUQ"
   },
   "source": [
    "a. Experiment Design\n",
    "\n",
    "Objective: To investigate the impact of the length of word lists on the performance of the word list classifier.\n",
    "\n",
    "Variable: The independent variable is the length of the word lists used by the classifier. This variable will be manipulated to observe its impact on classifier performance (dependent variable).\n",
    "\n",
    "Classifier: Use the word list classifier (SimpleClassifier) with different word list lengths.\n",
    "\n",
    "Datasets: Utilize the training and testing datasets provided.\n",
    "\n",
    "Experiment Steps:\n",
    "\n",
    "1. Create word lists of varying lengths, ranging from a small number of representative words to more extensive lists (10 - 1000).\n",
    "\n",
    "2. Train the word list classifier with each set of word lists.\n",
    "\n",
    "3. Evaluate, record and analyze the classifier's accuracy on the testing dataset for each word list length.\n",
    "\n",
    "4. Interpret the plotted graph: Observe how accuracy changes with the length of the wordlist. Look for patterns or trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of Word List Classifier (Size 10) is 0.49666666666666665\n",
      "The accuracy of Word List Classifier (Size 20) is 0.5466666666666666\n",
      "The accuracy of Word List Classifier (Size 50) is 0.5016666666666667\n",
      "The accuracy of Word List Classifier (Size 100) is 0.5\n",
      "The accuracy of Word List Classifier (Size 150) is 0.5\n",
      "The accuracy of Word List Classifier (Size 200) is 0.5\n",
      "The accuracy of Word List Classifier (Size 500) is 0.5\n",
      "The accuracy of Word List Classifier (Size 1000) is 0.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word List Size</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.496667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>0.546667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>0.501667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>200</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>500</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Word List Size  Accuracy\n",
       "0              10  0.496667\n",
       "1              20  0.546667\n",
       "2              50  0.501667\n",
       "3             100  0.500000\n",
       "4             150  0.500000\n",
       "5             200  0.500000\n",
       "6             500  0.500000\n",
       "7            1000  0.500000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Experiment parameters\n",
    "word_list_sizes = [10, 20, 50, 100, 150, 200, 500, 1000]\n",
    "results = []\n",
    "\n",
    "# Get the training and testing data\n",
    "training_data, testing_data = get_train_test_data()\n",
    "\n",
    "# Perform the experiment for different word list sizes\n",
    "for size in word_list_sizes:\n",
    "    # Convert StreamBackedCorpusView to list before sampling\n",
    "    positive_words = random.sample(list(movie_reviews.words(categories='pos')), size)\n",
    "    negative_words = random.sample(list(movie_reviews.words(categories='neg')), size)\n",
    "\n",
    "    classifier = SimpleClassifier(positive_words[:size], negative_words[:size])\n",
    "    accuracy = classifier_evaluate(classifier, testing_data)\n",
    "\n",
    "\n",
    "    print(\"The accuracy of Word List Classifier (Size {}) is {}\".format(size, accuracy))\n",
    "    results.append((size, accuracy))\n",
    "\n",
    "# Create a DataFrame and plot the results\n",
    "df = pd.DataFrame(results, columns=['Word List Size', 'Accuracy'])\n",
    "display(df)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(df['Word List Size'], df['Accuracy'])\n",
    "plt.title(\"Impact of Word List Size on Classifier Accuracy\")\n",
    "plt.xlabel(\"Word List Size\")\n",
    "plt.ylabel(\"Classifier Accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment Conclusions: \n",
    "\n",
    "Initially, as the size of the word list increases from 10 to 20, there is a noticeable improvement in accuracy. However, beyond size 20, the accuracy remains relatively stable, hovering around 0.5. This suggests that the classifier's performance plateaus, indicating that the classifier is performing no better than random chance, and adding more words beyond a certain threshold doesn't significantly enhance its accuracy. \n",
    "\n",
    "It is important to note that accuracy alone may not provide a comprehensive evaluation, and future considerations should involve exploring additional performance metrics such as precision, recall, and F1 score. These metrics can provide a more nuanced understanding of the classifier's strengths and weaknesses, particularly in handling false positives and false negatives. \n",
    "\n",
    "Additionally, investigating the impact of different feature extraction methods or incorporating more sophisticated classifiers could contribute to refining the model further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. For future work in the area of sentiment analysis, a Naive Bayes classifier is recommended over a wordlist classifier. While wordlist classifiers are simple and intuitive, they often lack the ability to capture the nuanced relationships and context-dependent nature of language. \n",
    "\n",
    "Naive Bayes classifiers, on the other hand, can leverage statistical patterns in the data and consider the joint probabilities of words, making them more adaptable to varying linguistic structures. They can handle a larger feature space and are better equipped to generalize from the training data to make predictions on unseen examples. \n",
    "\n",
    "Additionally, Naive Bayes classifiers inherently account for the likelihood of word co-occurrences, providing a more sophisticated approach to sentiment analysis that can yield improved accuracy and generalization in the classification of positive and negative sentiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ym-TGvYS2XUR"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34rdlS_iPov6",
    "outputId": "5465e8f3-ec02-4ff6-b326-0bf15c507b73",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission length is 862\n"
     ]
    }
   ],
   "source": [
    "##This code will word count all of the markdown cells in the notebook saved at filepath\n",
    "\n",
    "import io\n",
    "from nbformat import current\n",
    "\n",
    "\n",
    "filepath=\"/Users/tyrakoranteng/Downloads/ANLP Assignment (1).ipynb\"\n",
    "question_count=432\n",
    "\n",
    "with io.open(filepath, 'r', encoding='utf-8') as f:\n",
    "    nb = current.read(f, 'json')\n",
    "\n",
    "word_count = 0\n",
    "for cell in nb.worksheets[0].cells:\n",
    "    if cell.cell_type == \"markdown\":\n",
    "        word_count += len(cell['source'].replace('#', '').lstrip().split(' '))\n",
    "print(\"Submission length is {}\".format(word_count-question_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
